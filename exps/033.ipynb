{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ランク学習\n",
    "# 学習データ5週分(検証データ1週含む)\n",
    "# 候補作り12週分\n",
    "# trendingで候補作り\n",
    "# articlesとcustomersの特徴量をtarget_weekごとに作る\n",
    "# 候補の良さを測る\n",
    "# 顧客毎の最終週で候補作り\n",
    "# コラボ商品で候補作り\n",
    "# 説明文KNN(tsne, 重複除外なし)\n",
    "# ペア商品\n",
    "# New: コラボのtarget_week=-1修正したやつ\n",
    "# MAP@12 (all): 0.032276\n",
    "# MAP@12 (cold start): 0.006463\n",
    "EXP = '033'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from psutil import cpu_count\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import gc\n",
    "import os\n",
    "from time import time\n",
    "import warnings\n",
    "from functools import reduce\n",
    "\n",
    "tqdm.pandas()\n",
    "pd.options.display.max_columns = None\n",
    "warnings.simplefilter('ignore', pd.errors.PerformanceWarning)\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "data_path = Path('../input/h-and-m-personalized-fashion-recommendations/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31788324, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>t_diff</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31788319</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>1371691</td>\n",
       "      <td>929511001</td>\n",
       "      <td>0.059305</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31788320</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>1371691</td>\n",
       "      <td>891322004</td>\n",
       "      <td>0.042356</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31788321</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>1371721</td>\n",
       "      <td>918325001</td>\n",
       "      <td>0.043203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31788322</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>1371747</td>\n",
       "      <td>833459002</td>\n",
       "      <td>0.006763</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31788323</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>1371960</td>\n",
       "      <td>898573003</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              t_dat  customer_id  article_id     price  sales_channel_id  \\\n",
       "31788319 2020-09-22      1371691   929511001  0.059305                 2   \n",
       "31788320 2020-09-22      1371691   891322004  0.042356                 2   \n",
       "31788321 2020-09-22      1371721   918325001  0.043203                 1   \n",
       "31788322 2020-09-22      1371747   833459002  0.006763                 1   \n",
       "31788323 2020-09-22      1371960   898573003  0.033881                 2   \n",
       "\n",
       "          t_diff  week  \n",
       "31788319       0     0  \n",
       "31788320       0     0  \n",
       "31788321       0     0  \n",
       "31788322       0     0  \n",
       "31788323       0     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transactions = pd.read_csv(\n",
    "    data_path / f'transactions_train.csv',\n",
    "    # set dtype or pandas will drop the leading '0' and convert to int\n",
    "    dtype={'article_id': 'int32'},\n",
    "    parse_dates=['t_dat'])\n",
    "customers = pd.read_csv(data_path / 'customers.csv')\n",
    "articles = pd.read_csv(\n",
    "    '../input/h-and-m-personalized-fashion-recommendations/articles.csv', \n",
    "    dtype={'article_id': 'int32'})\n",
    "\n",
    "t_max = transactions['t_dat'].max()\n",
    "transactions['t_diff'] = (t_max - transactions['t_dat']).dt.days\n",
    "transactions['week'] = transactions['t_diff'] // 7\n",
    "\n",
    "# Noneの表記不揃い対策\n",
    "customers.loc[~customers['fashion_news_frequency'].isin(['Regularly', 'Monthly']), 'fashion_news_frequency'] = None\n",
    "\n",
    "# メモリ削減\n",
    "id_to_index_dict = dict(zip(customers[\"customer_id\"], customers.index))\n",
    "index_to_id_dict = dict(zip(customers.index, customers[\"customer_id\"]))\n",
    "transactions[\"customer_id\"] = transactions[\"customer_id\"].map(id_to_index_dict).astype('int32')\n",
    "customers['customer_id'] = customers['customer_id'].map(id_to_index_dict).astype('int32')\n",
    "\n",
    "print(transactions.shape)\n",
    "display(transactions.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates_trending(transactions: pd.DataFrame, customers: np.ndarray, target_week: int):\n",
    "    # week列のシフト(week=target_week => week=0)、リーク防止\n",
    "    df = transactions.query(\"customer_id in @customers\").copy()\n",
    "    df['week'] = df['week'] - target_week\n",
    "    df = df.query('week >= 1')\n",
    "    \n",
    "    # 以下のロジックはtrendingの公開カーネル参照\n",
    "    weekly_sales = df.groupby(['week', 'article_id'])['article_id'].count().rename('count').reset_index()\n",
    "    df = df.merge(weekly_sales, on=['week', 'article_id'], how='left')    \n",
    "    weekly_sales = weekly_sales.reset_index().set_index('article_id')\n",
    "    df = df.join(weekly_sales.loc[weekly_sales['week']==1, ['count']], on='article_id', rsuffix='_targ')\n",
    "    df['count_targ'].fillna(0, inplace=True)\n",
    "    df['quotient'] = df['count_targ'] / df['count']\n",
    "    \n",
    "    t_max = df['t_dat'].max()\n",
    "    df['x'] = ((t_max - df['t_dat']) / np.timedelta64(1, 'D')).astype(int)\n",
    "    df['dummy_1'] = 1\n",
    "    df['x'] = df[['x', 'dummy_1']].max(axis=1)    \n",
    "    a, b, c, d = 2.5e4, 1.5e5, 2e-1, 1e3\n",
    "    df['y'] = a / np.sqrt(df['x']) + b * np.exp(-c*df['x']) - d\n",
    "    df['dummy_0'] = 0 \n",
    "    df['y'] = df[[\"y\", \"dummy_0\"]].max(axis=1)\n",
    "    df['trending_value'] = df['quotient'] * df['y']\n",
    "    df = df.groupby(['customer_id', 'article_id']).agg({'trending_value': 'sum'}).reset_index()\n",
    "    df = df.loc[df['trending_value'] > 0]\n",
    "    # df['rank'] = df.groupby(\"customer_id\")[\"value\"].rank(\"dense\", ascending=False)\n",
    "    # df = df.loc[df['rank'] <= 12]\n",
    "    \n",
    "    df['isin_trending'] = 1\n",
    "\n",
    "    return df[['customer_id', 'article_id', 'trending_value', 'isin_trending']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates_recently(transactions: pd.DataFrame, customers: np.ndarray, target_week: int):\n",
    "    '''直近の購入履歴から候補生成'''\n",
    "    # week列のシフト(week=target_week => week=0)、リーク防止\n",
    "    df = transactions.query(\"customer_id in @customers\").copy()\n",
    "    df['week'] = df['week'] - target_week\n",
    "    df = df.query(\"week >= 1\")\n",
    "    df = df.query(\"week <= 12\")  # 12週分の履歴を使用\n",
    "    \n",
    "    # 各週の購入個数から特徴量\n",
    "    for w in df['week'].unique()[::-1]:\n",
    "        tmp = df.query('week == @w').groupby(['customer_id', 'article_id'])['article_id'].count().rename(f'count_{w}w').reset_index().copy()\n",
    "        if w == 1:\n",
    "            purchase_df = tmp\n",
    "            continue\n",
    "        purchase_df = purchase_df.merge(tmp, how='outer', on=['customer_id', 'article_id'])\n",
    "        \n",
    "    purchase_df['isin_recently'] = 1\n",
    "    \n",
    "    return purchase_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates_popular(transactions: pd.DataFrame, customers: np.ndarray, target_week: int):\n",
    "    '''販売数の多い商品から候補生成'''\n",
    "    # make_articles_featureが販売数から特徴量を作ってくれるから、この関数は候補のペアだけ返す\n",
    "    \n",
    "    # week列のシフト(week=target_week => week=0)、リーク防止\n",
    "    df = transactions.copy()\n",
    "    df['week'] = df['week'] - target_week\n",
    "    df = df.query(\"week >= 1\")\n",
    "    df = df.query(\"week <= 4\")  # 4週分の履歴を使用\n",
    "\n",
    "    # 各週の販売数上位12個\n",
    "    dummy_count_df = df.groupby(['article_id', 'week'])['week'].count().rename('dummy_count').reset_index().copy()\n",
    "    dummy_count_df['rank_in_week'] = dummy_count_df.groupby('week')['dummy_count'].rank(method='min', ascending=False)\n",
    "    dummy_articles = dummy_count_df.query('rank_in_week <= 12')['article_id'].unique()\n",
    "\n",
    "    dummy_df = pd.DataFrame(\n",
    "        np.concatenate(\n",
    "            [np.repeat(customers, repeats=len(dummy_articles)).reshape(-1, 1),\n",
    "            np.repeat(dummy_articles[None, :], repeats=len(customers), axis=0).reshape(-1, 1)],\n",
    "            axis=1),\n",
    "        columns = ['customer_id', 'article_id']\n",
    "    )\n",
    "    \n",
    "    dummy_df['isin_popular'] = 1\n",
    "    \n",
    "    return dummy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates_lastw(transactions: pd.DataFrame, customers: np.ndarray, target_week: int):\n",
    "    '''customer毎の最後の購入から1週間の購入履歴から候補生成'''\n",
    "    # week列のシフト(week=target_week => week=0)、リーク防止\n",
    "    df = transactions.query(\"customer_id in @customers\").copy()\n",
    "    df['week'] = df['week'] - target_week\n",
    "    df = df.query(\"week >= 1\").copy()\n",
    "\n",
    "    # 最後の購入から1週間に絞る\n",
    "    df['max_dat'] = df['customer_id'].map(df.groupby('customer_id')['t_dat'].max())\n",
    "    df['max_diff'] = (df['max_dat'] - df['t_dat']).dt.days\n",
    "    df = df.query('max_diff <= 6')\n",
    "    \n",
    "    df = df.merge(df.groupby(['customer_id', 'article_id'])['article_id'].count().rename('count_lastw').reset_index(), on=['customer_id', 'article_id'])\n",
    "    df = df.sort_values('t_dat', ascending=True)\n",
    "    df = df.drop_duplicates(['customer_id', 'article_id'], keep='last')\n",
    "    df = df.rename(columns={'t_dat': 'last_dat'})\n",
    "    df['last_dat'] = df['last_dat'].astype(np.int64) // 10 ** 9\n",
    "    \n",
    "    df['isin_lastw'] = 1\n",
    "    \n",
    "    return df[['customer_id', 'article_id', 'count_lastw', 'last_dat', 'isin_lastw']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates_pair(transactions: pd.DataFrame, customers: np.ndarray, target_week: int):\n",
    "    '''ルールベース協調フィルタリングから候補生成'''\n",
    "    # week列のシフト(week=target_week => week=0)、リーク防止\n",
    "    df = transactions.query(\"customer_id in @customers\").copy()\n",
    "    df['week'] = df['week'] - target_week\n",
    "    df = df.query(\"week >= 1\")\n",
    "    df = df.query('week <= 4').copy()  # 4週分の履歴を使用\n",
    "    \n",
    "    df = df.merge(df.groupby(['customer_id', 'article_id'])['article_id'].count().rename('count').reset_index(), on=['customer_id', 'article_id'])\n",
    "    df = df.drop_duplicates(['customer_id', 'article_id'], keep='last')\n",
    "    pairs = pd.read_parquet(f'../input/hmitempairs/pairs_fold{target_week}_5items.parquet')\n",
    "    df = df.merge(pairs, on='article_id', how='inner')\n",
    "    df = df.drop('article_id', axis=1).rename(columns={'pair_article_id': 'article_id'})\n",
    "    df['count_pair'] = df['count'] * df['pair_ratio']\n",
    "\n",
    "    df['isin_pair'] = 1\n",
    "\n",
    "    return df[['customer_id', 'article_id', 'count_pair', 'isin_pair']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_candidates_collabo\u001b[39m(transactions: \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame, customers: np\u001b[38;5;241m.\u001b[39mndarray, target_week: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124;03m'''コラボ商品の購入履歴から候補生成'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../input/ranking_features/collabo_candidate_with_nseries.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marticle_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_candidates_collabo(transactions: pd.DataFrame, customers: np.ndarray, target_week: int):\n",
    "    '''コラボ商品の購入履歴から候補生成'''\n",
    "    df = pd.read_csv('../input/ranking_features/collabo_candidate_with_nseries.csv', dtype={'article_id': 'int32'})\n",
    "    # FIXME: ほんとはスコープ外変数の参照は良くない\n",
    "    df['customer_id'] = df['customer_id'].map(id_to_index_dict).astype('int32')\n",
    "    df = df.query('customer_id in @customers').copy()\n",
    "    df = df.query('target_week == @target_week').copy()\n",
    "    \n",
    "    df['isin_collabo'] = 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_candidates_desc_knn(transactions: pd.DataFrame, customers: np.ndarray, target_week: int, encoder: str):\n",
    "    '''説明文の埋め込みベクトル（次元削減済み）から候補生成'''\n",
    "    # week列のシフト(week=target_week => week=0)、リーク防止\n",
    "    df = transactions.query(\"customer_id in @customers\").copy()\n",
    "    df['week'] = df['week'] - target_week\n",
    "    df = df.query(\"week >= 1\")\n",
    "    df = df.query('week <= 4').copy()  # 4週分の履歴を使用\n",
    "    df = df.groupby(['customer_id', 'article_id'])['article_id'].count().rename('count').reset_index()\n",
    "    \n",
    "    desc_knn = pd.read_csv(f'../input/ranking_features/item_features_{encoder}_class.csv', dtype={'article_id': 'int32'})\n",
    "    \n",
    "    dfs = []\n",
    "    for i in range(5):\n",
    "        dfs.append(df.merge(desc_knn[['article_id', f'knn_article_id_{i}', f'knn_distance_{i}']])\n",
    "                        .rename(columns={f'knn_article_id_{i}': 'knn_article_id', f'knn_distance_{i}': f'{encoder}_distance'}))\n",
    "    df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    df = df.drop('article_id', axis=1).rename(columns={'knn_article_id': 'article_id'})\n",
    "    df[f'{encoder}_count'] = df['count'] * df[f'{encoder}_distance']\n",
    "    \n",
    "    # # 重複を削除、item1とitem2それぞれの類似として同じitemが出てくることがある\n",
    "    # df = df.sort_values(f'{encoder}_count', ascending=True).drop_duplicates(subset=['customer_id', 'article_id'], keep='first')\n",
    "    \n",
    "    df[f'isin_{encoder}_knn'] = 1\n",
    "                   \n",
    "    return df[['customer_id', 'article_id', f'{encoder}_count', f'{encoder}_distance', f'isin_{encoder}_knn']]\n",
    "\n",
    "def _generate_candidates_albert_knn(transactions: pd.DataFrame, customers: np.ndarray, target_week: int):\n",
    "    # week列のシフト(week=target_week => week=0)、リーク防止\n",
    "    df = transactions.query(\"customer_id in @customers\").copy()\n",
    "    df['week'] = df['week'] - target_week\n",
    "    df = df.query(\"week >= 1\")\n",
    "    df = df.query('week <= 4').copy()  # 4週分の履歴を使用\n",
    "    df = df.groupby(['customer_id', 'article_id'])['article_id'].count().rename('count').reset_index()\n",
    "\n",
    "    albert_knn = pd.read_csv('../input/ranking_features/Albert_cos.csv', dtype={'article': 'int32', 'knn_article': 'int32'})\n",
    "    albert_knn = albert_knn.rename(columns={'article': 'article_id'})\n",
    "    \n",
    "    df = df.merge(albert_knn)\n",
    "    df = df.drop('article_id', axis=1).rename(columns={'knn_article': 'article_id', 'distances': 'albert_distance'})\n",
    "    df['albert_count'] = df['count'] * abs(1-df['albert_distance'])\n",
    "    \n",
    "    df['isin_albert_knn'] = 1\n",
    "    \n",
    "    return df[['customer_id', 'article_id', 'albert_count', 'albert_distance', 'isin_albert_knn']]\n",
    "\n",
    "def generate_candidates_desc_knn(transactions: pd.DataFrame, customers: np.ndarray, target_week: int):\n",
    "    '''商品説明文から候補生成'''\n",
    "    tsne_df = _generate_candidates_desc_knn(transactions, customers, target_week, encoder='tsne')\n",
    "    # umap_df = _generate_candidates_desc_knn(transactions, customers, target_week, encoder='umap')\n",
    "    # albert_df = _generate_candidates_albert_knn(transactions, customers, target_week)\n",
    "    # df = pd.merge(tsne_df, albert_df, how='outer', on=['customer_id', 'article_id'])\n",
    "\n",
    "    return tsne_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates_im_knn(transactions: pd.DataFrame, customers: np.ndarray, target_week: int, encoder: str):\n",
    "    '''画像の埋め込みベクトル（次元削減済み）から候補生成'''\n",
    "    # week列のシフト(week=target_week => week=0)、リーク防止\n",
    "    df = transactions.query(\"customer_id in @customers\").copy()\n",
    "    df['week'] = df['week'] - target_week\n",
    "    df = df.query(\"week >= 1\")\n",
    "    df = df.query('week <= 4').copy()  # 4週分の履歴を使用\n",
    "    df = df.groupby(['customer_id', 'article_id'])['article_id'].count().rename('count').reset_index()\n",
    "    \n",
    "    im_knn = pd.read_parquet(f'../input/ranking_features/candidates_knn_{encoder}.parquet', dtype={'article_id': 'int32'})\n",
    "    \n",
    "    df = df.drop('article_id', axis=1).rename(columns={'knn_im_article_id': 'article_id', 'knn_im_distance': f'{encoder}_distance'})\n",
    "    df[f'{encoder}_count'] = df['count'] * df[f'knn_im_distance']\n",
    "    \n",
    "    # # 重複を削除、item1とitem2それぞれの類似として同じitemが出てくることがある\n",
    "    # df = df.sort_values(f'{encoder}_count', ascending=True).drop_duplicates(subset=['customer_id', 'article_id'], keep='first')\n",
    "    \n",
    "    df[f'isin_{encoder}_knn'] = 1\n",
    "                   \n",
    "    return df[['customer_id', 'article_id', f'{encoder}_count', f'{encoder}_distance', f'isin_{encoder}_knn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_customers_feature(customers: pd.DataFrame, transactions: pd.DataFrame, target_week: int, debug: bool = False):\n",
    "    '''customer毎に特徴量エンジニアリング'''\n",
    "    df = transactions.copy()\n",
    "    customers_feature = customers.drop(['postal_code'], axis=1).copy()\n",
    "    customers_feature.loc[~customers_feature['fashion_news_frequency'].isin(['Regularly', 'Monthly']), 'fashion_news_frequency'] = None  # Noneの表記揃え\n",
    "    customers_feature[['FN', 'Active']] = customers_feature[['FN', 'Active']].fillna(0)\n",
    "\n",
    "    # week列のシフト(week=target_week => week=0)、リーク防止\n",
    "    df['week'] = df['week'] - target_week\n",
    "    df = df.query('week >= 1')\n",
    "    if debug == True:\n",
    "        df = df.query('week <= 24')\n",
    "\n",
    "    weekly_purchase = df.groupby(['customer_id', 'week'])['week'].count().rename('purchase').reset_index()\n",
    "    \n",
    "    # 統計量で特徴量\n",
    "    for agg_name in ['max', 'min', 'mean', 'sum']:\n",
    "        agg_sr = weekly_purchase.groupby('customer_id')['purchase'].agg(agg_name)\n",
    "        customers_feature[f'purchase_{agg_name}_groupby_customer'] = customers_feature['customer_id'].map(agg_sr)\n",
    "    \n",
    "    # 各週の購入数、統計量との差、比で特徴量\n",
    "    for w in df['week'].unique()[::-1]:\n",
    "        tmp = weekly_purchase[weekly_purchase['week']==w]\n",
    "        tmp = tmp[['customer_id', 'purchase']].set_index('customer_id')['purchase']\n",
    "        customers_feature[f'purchase_{w}w'] = customers_feature['customer_id'].map(tmp).fillna(0)\n",
    "        for agg_name in ['max', 'min', 'mean', 'sum']:\n",
    "            customers_feature[f'purchase_{agg_name}_groupby_customer_ratio_{w}w'] = customers_feature[f'purchase_{w}w'] / customers_feature[f'purchase_{agg_name}_groupby_customer']\n",
    "            customers_feature[f'purchase_{agg_name}_groupby_customer_diff_{w}w'] = customers_feature[f'purchase_{w}w'] - customers_feature[f'purchase_{agg_name}_groupby_customer']\n",
    "\n",
    "    # --- 一意の(article_id, week)を購入単位とみなす ---\n",
    "    # ※あるarticleを1個買うことを、ふつうは購入単位とみなしている\n",
    "    # rank: 何回目の購入か\n",
    "    unique_transactions = df[['customer_id', 'article_id', 'week']].drop_duplicates()\n",
    "    unique_transactions['rank'] = unique_transactions.groupby(['customer_id', 'article_id'])['week'].rank(method='dense', ascending=False)\n",
    "\n",
    "    # 再購入したarticleの割合\n",
    "    customers_feature['repurchase_article'] = customers_feature['customer_id'].map(\n",
    "        unique_transactions.query('rank >= 2').drop_duplicates(subset=['customer_id', 'article_id']).groupby('customer_id')['article_id'].count()).fillna(0)\n",
    "    customers_feature['purchase_article'] = customers_feature['customer_id'].map(unique_transactions.drop_duplicates(subset=['customer_id', 'article_id']).groupby('customer_id')['article_id'].count())\n",
    "    customers_feature['repurchase_article_percent'] = customers_feature['repurchase_article'] / customers_feature['purchase_article']\n",
    "\n",
    "    # 再購入を含む週の割合\n",
    "    customers_feature['repurchase_week'] = customers_feature['customer_id'].map(\n",
    "        unique_transactions.query('rank >= 2').drop_duplicates(subset=['customer_id', 'week']).groupby('customer_id')['week'].count()).fillna(0)\n",
    "    customers_feature['purchase_week'] = customers_feature['customer_id'].map(\n",
    "        unique_transactions.drop_duplicates(subset=['customer_id', 'week']).groupby('customer_id')['week'].count())\n",
    "    customers_feature['repurchase_week_percent'] = customers_feature['repurchase_week'] / customers_feature['purchase_week']\n",
    "    \n",
    "    # 再購入の割合\n",
    "    customers_feature['repurchase_article_and_week'] = customers_feature['customer_id'].map(\n",
    "        unique_transactions.query('rank >= 2').groupby('customer_id')['customer_id'].count()).fillna(0)\n",
    "    customers_feature['purchase_article_and_week'] = customers_feature['customer_id'].map(\n",
    "        unique_transactions.groupby('customer_id')['customer_id'].count())\n",
    "    customers_feature['repurchase_article_and_week_percent'] = customers_feature['repurchase_article_and_week'] / customers_feature['purchase_article_and_week']\n",
    "    # --- おわり ---\n",
    "    \n",
    "    return customers_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_articles_feature(articles: pd.DataFrame, transactions: pd.DataFrame, target_week: int, debug: bool = False):\n",
    "    '''article毎に特徴量エンジニアリング'''\n",
    "    df = transactions.copy()\n",
    "    articles_feature = articles.drop(\n",
    "        ['prod_name', 'product_type_name', 'graphical_appearance_name', 'colour_group_name', 'perceived_colour_value_name', 'perceived_colour_master_name', 'index_name', 'index_group_name', 'section_name', 'garment_group_name', 'prod_name', 'department_name', 'detail_desc'], \n",
    "        axis=1).copy()\n",
    "    \n",
    "    # week列のシフト(week=target_week => week=0)、リーク防止\n",
    "    df['week'] = df['week'] - target_week\n",
    "    df = df.query('week >= 1')\n",
    "    \n",
    "    if debug == True:\n",
    "        df = df.query('week <= 24')\n",
    "\n",
    "    weekly_sale = df.groupby(['article_id', 'week'])['week'].count().rename('sale').reset_index()\n",
    "    \n",
    "    # 統計量で特徴量\n",
    "    for agg_name in ['max', 'min', 'mean', 'sum']:\n",
    "        agg_sr = weekly_sale.groupby('article_id')['sale'].agg(agg_name)\n",
    "        articles_feature[f'sale_{agg_name}_groupby_article'] = articles_feature['article_id'].map(agg_sr)\n",
    "\n",
    "    # 各週の販売数、統計量との差、比で特徴量\n",
    "    for w in df['week'].unique()[::-1]:\n",
    "        tmp = weekly_sale[weekly_sale['week']==w]\n",
    "        tmp = tmp[['article_id', 'sale']].set_index('article_id')['sale']\n",
    "        articles_feature[f'sale_{w}w'] = articles_feature['article_id'].map(tmp).fillna(0)\n",
    "        for agg_name in ['max', 'min', 'mean', 'sum']:\n",
    "            articles_feature[f'sale_{agg_name}_groupby_article_ratio_{w}w'] = articles_feature[f'sale_{w}w'] / articles_feature[f'sale_{agg_name}_groupby_article']\n",
    "            articles_feature[f'sale_{agg_name}_groupby_article_diff_{w}w'] = articles_feature[f'sale_{w}w'] - articles_feature[f'sale_{agg_name}_groupby_article']\n",
    "\n",
    "    # --- 一意の(customer_id, week)を販売単位とみなす ---\n",
    "    # ※あるcustomerに1つ売れることを、ふつうは販売単位とみなしている\n",
    "    # rank: 何回目の販売か\n",
    "    unique_transactions = df[['article_id', 'customer_id', 'week']].drop_duplicates()\n",
    "    unique_transactions['rank'] = unique_transactions.groupby(['article_id', 'customer_id'])['week'].rank(method='dense', ascending=False)\n",
    "\n",
    "    # 再販売したcustomerの割合\n",
    "    articles_feature['resale_customer'] = articles_feature['article_id'].map(\n",
    "        unique_transactions.query('rank >= 2').drop_duplicates(subset=['article_id', 'customer_id']).groupby('article_id')['customer_id'].count()).fillna(0)\n",
    "    articles_feature['sale_customer'] = articles_feature['article_id'].map(unique_transactions.drop_duplicates(subset=['article_id', 'customer_id']).groupby('article_id')['customer_id'].count())\n",
    "    articles_feature['resale_customer_percent'] = articles_feature['resale_customer'] / articles_feature['sale_customer']\n",
    "\n",
    "    # 再販売を含む週の割合\n",
    "    articles_feature['resale_week'] = articles_feature['article_id'].map(\n",
    "        unique_transactions.query('rank >= 2').drop_duplicates(subset=['article_id', 'week']).groupby('article_id')['week'].count()).fillna(0)\n",
    "    articles_feature['sale_week'] = articles_feature['article_id'].map(\n",
    "        unique_transactions.drop_duplicates(subset=['article_id', 'week']).groupby('article_id')['week'].count())\n",
    "    articles_feature['resale_week_percent'] = articles_feature['resale_week'] / articles_feature['sale_week']\n",
    "\n",
    "    # 再販売の割合\n",
    "    articles_feature['resale_customer_and_week'] = articles_feature['article_id'].map(\n",
    "        unique_transactions.query('rank >= 2').groupby('article_id')['article_id'].count()).fillna(0)\n",
    "    articles_feature['sale_customer_and_week'] = articles_feature['article_id'].map(\n",
    "        unique_transactions.groupby('article_id')['article_id'].count())\n",
    "    articles_feature['resale_customer_and_week_percent'] = articles_feature['resale_customer_and_week'] / articles_feature['sale_customer_and_week']\n",
    "    # --- 終わり ---\n",
    "    \n",
    "    return articles_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_df(transactions: pd.DataFrame, week: int, is_labeled: bool, use_customers: np.ndarray = None, metric_verbose: bool = True, compress_verbose: bool = False):\n",
    "    '''ランク学習モデルへの入力データ作成'''\n",
    "    # WARNING: 戦略を追加した時に書き換え忘れ注意！\n",
    "    strategy_flags = [\n",
    "        'isin_trending', \n",
    "        'isin_recently', \n",
    "        'isin_popular', \n",
    "        'isin_lastw', \n",
    "        'isin_pair', \n",
    "        'isin_collabo', \n",
    "        'isin_tsne_knn', \n",
    "        # 'isin_albert_knn',\n",
    "        # 'isin_vgg_knn',\n",
    "    ]\n",
    "    kwargs = {'how': 'outer', 'on': ['customer_id', 'article_id'], 'copy': True}\n",
    "    \n",
    "    # 入力データに含むcustomersの絞り込み\n",
    "    if use_customers is not None:\n",
    "        data_customers = use_customers\n",
    "    elif week >= 0:\n",
    "        data_customers = transactions.query(\"week == @week\")['customer_id'].unique()\n",
    "    else:\n",
    "        raise ValueError('set use_customers as something when week=-1.')\n",
    "    \n",
    "    # 候補作り\n",
    "    data_dfs = []\n",
    "    data_dfs.append(generate_candidates_trending(transactions, data_customers, week))\n",
    "    data_dfs.append(generate_candidates_recently(transactions, data_customers, week))\n",
    "    data_dfs.append(generate_candidates_popular(transactions, data_customers, week))\n",
    "    data_dfs.append(generate_candidates_lastw(transactions, data_customers, week))\n",
    "    data_dfs.append(generate_candidates_pair(transactions, data_customers, week))\n",
    "    data_dfs.append(generate_candidates_collabo(transactions, data_customers, week))\n",
    "    data_dfs.append(generate_candidates_desc_knn(transactions, data_customers, week))\n",
    "    # data_dfs.append(generate_candidates_im_knn(transactions, data_customers, week))\n",
    "    \n",
    "    data_df = reduce(\n",
    "        lambda  left,right: pd.merge(left, right, on=['customer_id', 'article_id'], how='outer'), \n",
    "        data_dfs)\n",
    "\n",
    "    data_df[strategy_flags] = data_df[strategy_flags].fillna(0)\n",
    "    \n",
    "    # 正解ラベル付け\n",
    "    if is_labeled:\n",
    "        if week < 0:\n",
    "            raise ValueError(f\"can't label when week={week}.\")\n",
    "        data_actual = transactions.query(\"week == @week\")[['customer_id', 'article_id']].drop_duplicates()\n",
    "        data_actual['label'] = 1\n",
    "        data_df = data_df.merge(data_actual, how='left', on=['customer_id', 'article_id'])\n",
    "        data_df['label'] = data_df['label'].fillna(0)\n",
    "    \n",
    "    # customers, articles の特徴量\n",
    "    data_df = compress_df(data_df, verbose=compress_verbose)\n",
    "    data_customers_feature = compress_df(\n",
    "        make_customers_feature(customers, transactions, target_week=week, debug=True), \n",
    "        verbose=compress_verbose)\n",
    "    data_articles_feature = compress_df(\n",
    "        make_articles_feature(articles, transactions, target_week=week, debug=True), \n",
    "        verbose=compress_verbose)\n",
    "    data_df = data_df.merge(data_customers_feature, how='left', on=['customer_id'])\n",
    "    data_df = data_df.merge(data_articles_feature, how='left', on=['article_id'])\n",
    "    # data_df = compress_df(data_df, verbose=compress_verbose)\n",
    "    \n",
    "    # 候補のスコア\n",
    "    if metric_verbose:\n",
    "        print(f\"[Info] shape     : {data_df.shape}\")\n",
    "        print(f\"[Info] mem       : {data_df.memory_usage().sum() / 1024**2 :5.2f} Mb\")\n",
    "        print(f\"[Info] candidates: {len(data_df) / len(data_customers):.1f} 個 / customer\")\n",
    "        display(data_df[strategy_flags].astype(float).mean())\n",
    "        if is_labeled:\n",
    "            print(f\"[Info] Precision: {data_df['label'].sum() / len(data_df):.5f}\")\n",
    "            print(f\"[Info] Recall   : {data_df['label'].sum() / len(data_actual):.5f}\")\n",
    "\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_df(\n",
    "    df: pd.DataFrame, \n",
    "    category_columns: list =['club_member_status', 'fashion_news_frequency', 'product_group_name', 'index_code'], \n",
    "    verbose: bool =True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    '''DataFrameのデータ型を適切に選び圧縮'''\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        bar = tqdm(df.columns, leave=False)\n",
    "    else:\n",
    "        bar = df.columns\n",
    "    for col in bar:\n",
    "        col_type = df[col].dtypes\n",
    "        if col in category_columns:\n",
    "            if verbose:\n",
    "                bar.set_description(f\"{col}(category)\")\n",
    "            df[col] = df[col].astype('category')\n",
    "        elif col_type in numerics:\n",
    "            if verbose:\n",
    "                bar.set_description(f\"{col}(num)\")\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(params: dict, cols: list, tr_df: pd.DataFrame, val_df: pd.DataFrame = None, early_stopping: bool = True):\n",
    "    if val_df is None:\n",
    "        tr_df = tr_df.sort_values('customer_id').reset_index(drop=True)\n",
    "        train_query = tr_df.groupby('customer_id')['customer_id'].count().to_list()\n",
    "        dtrain = lgb.Dataset(tr_df[cols], label=tr_df['label'], group=train_query)\n",
    "        model = lgb.train(params, dtrain, valid_sets=[dtrain], callbacks=[lgb.log_evaluation(10)])\n",
    "\n",
    "    else:\n",
    "        tr_df = tr_df.sort_values('customer_id').reset_index(drop=True)\n",
    "        val_df = val_df.sort_values('customer_id').reset_index(drop=True)    \n",
    "        train_query = tr_df.groupby('customer_id')['customer_id'].count().to_list()\n",
    "        val_query = val_df.groupby('customer_id')['customer_id'].count().to_list()\n",
    "        dtrain = lgb.Dataset(tr_df[cols], label=tr_df['label'], group=train_query)\n",
    "        dval = lgb.Dataset(val_df[cols], reference=dtrain, label=val_df['label'], group=val_query)\n",
    "        if early_stopping:\n",
    "            model = lgb.train(params, dtrain, valid_sets=[dtrain, dval], callbacks=[lgb.early_stopping(10, first_metric_only=True), lgb.log_evaluation(10)])\n",
    "        else:\n",
    "            model = lgb.train(params, dtrain, valid_sets=[dtrain, dval], callbacks=[lgb.log_evaluation(10)])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_df: pd.DataFrame, model_folds: list):\n",
    "    pred = np.zeros(len(test_df))\n",
    "    for w in model_folds:\n",
    "        with open(f\"../models/lgb_rank/{EXP}_model_fold{w}.pkl\", 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "        pred += model.predict(test_df[cols], num_iteration=model.best_iteration)    \n",
    "    pred = pred/len(model_folds)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_top_sr(test_df: pd.DataFrame, pred: np.ndarray):\n",
    "    '''モデルのスコアを用いて並び替え＆上位12個抽出'''\n",
    "    test_df['predict_score'] = pred\n",
    "    test_df = test_df.sort_values('predict_score', ascending=False).drop_duplicates(['customer_id', 'article_id'], keep='first').reset_index(drop=True)\n",
    "    test_df['rank'] = test_df.groupby('customer_id')['predict_score'].rank('min', ascending=False)\n",
    "    test_df = test_df[test_df['rank'] <= 12]\n",
    "    \n",
    "    # test_df['article_id'] = le.inverse_transform(test_df['article_id'])\n",
    "    test_df['article_id'] = ' 0' + test_df['article_id'].astype(str)\n",
    "    \n",
    "    top_sr = test_df.groupby('customer_id')['article_id'].sum()\n",
    "    \n",
    "    return top_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # optunaによるチューニング\n",
    "# import optuna.integration.lightgbm as lgb_optuna\n",
    "# from optuna.logging import set_verbosity\n",
    "# import numpy as np\n",
    "# import random as rn\n",
    "\n",
    "# set_verbosity(-1)\n",
    "# np.random.seed(71)\n",
    "# rn.seed(71)\n",
    "\n",
    "# params = {\n",
    "#     'objective': 'lambdarank',\n",
    "#     'boosting': 'gbdt',  # default: 'gbdt', 'gbdt' or 'dart'\n",
    "#     'num_iterations': 1000,\n",
    "#     'learning_rate': 0.1,\n",
    "#     'metric': ['ndcg'],\n",
    "#     'eval_at': [12],  # 上位何件のランキングをnDCGとMAPの算出に用いるか\n",
    "#     'random_state': 71,  # 訓練用とは違う値にする\n",
    "#     'verbosity': -1,  # -1: ignore, 0: warnings, 1: info\n",
    "#     'deterministic': True,  # 再現性確保\n",
    "#     'force_row_wise': True  # 再現性確保\n",
    "# }\n",
    "\n",
    "# tr_df = make_data_df(transactions, 2, is_labeled=True, metric_verbose=False, compress_verbose=False)\n",
    "# exclude_columns = ['target_week', 'customer_id', 'article_id', 'label']\n",
    "# cols = [c for c in tr_df.columns.tolist() if c not in exclude_columns]\n",
    "# tr_df = tr_df.sort_values('customer_id').reset_index(drop=True)\n",
    "# train_query = tr_df.groupby('customer_id')['customer_id'].count().to_list()\n",
    "# dtrain = lgb.Dataset(tr_df[cols], label=tr_df['label'], group=train_query)\n",
    "\n",
    "# val_df = make_data_df(transactions, 1, is_labeled=True, metric_verbose=False, compress_verbose=False)\n",
    "# val_df = val_df.sort_values('customer_id').reset_index(drop=True)    \n",
    "# val_query = val_df.groupby('customer_id')['customer_id'].count().to_list()\n",
    "# dval = lgb.Dataset(val_df[cols], reference=dtrain, label=val_df['label'], group=val_query)\n",
    "\n",
    "# model = lgb_optuna.LightGBMTuner(params, dtrain, valid_sets=[dtrain, dval], early_stopping_rounds=10, verbose_eval=-1, optuna_seed=71)\n",
    "# model.run()\n",
    "\n",
    "# best_params = model.params\n",
    "# best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランク学習\n",
    "params = {\n",
    "    # Core Parameters\n",
    "    'objective': 'lambdarank',\n",
    "    'boosting': 'gbdt',  # default: 'gbdt', ['gbdt', 'dart', 'goss'], dart: 超遅いけど高精度\n",
    "    'num_iterations': 1000,\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 31,  # default: 31, large for accuracy\n",
    "    'num_threads': cpu_count(logical=False),\n",
    "    'random_state': 41,\n",
    "\n",
    "    # Learning Control Parameters\n",
    "    'force_col_wise': True,\n",
    "    # 'histogram_pool_size': -1.0,  # default: -1.0, max cache size in MB for historical histogram, (histogram_pool_size + dataset size) = approximately RAM used\n",
    "    'min_data_in_leaf': 20,  # default: 20, large dealing with over-fitting\n",
    "    'min_sum_hessian_in_leaf': 1e-3,  # default: 1e-3, large dealing with over-fitting\n",
    "    'max_depth': -1,\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'feature_fraction': 0.8,\n",
    "    # 'drop_rate': 0.1,  # used only in dart, a fraction of previous trees to drop during the dropout\n",
    "    'verbosity': 0,  # 0: warnings, 1: info\n",
    "\n",
    "    # Dataset Parameters\n",
    "    'max_bin': 255,  # default: 255, large for accuracy\n",
    "    'min_data_in_bin': 3,  # default: 3, \n",
    "    'bin_construct_sample_cnt': 200000,  # default: 200000, larger for accuracy\n",
    "\n",
    "    # Objective Parameters\n",
    "    'lambdarank_truncation_level': 30,\n",
    "    'lambdarank_norm': True,\n",
    "    # 'label_gain': [0, 1],\n",
    "\n",
    "    # Metric Parameters\n",
    "    'metric': ['ndcg'],\n",
    "    'eval_at': [12],  # 上位何件のランキングをnDCGとMAPの算出に用いるか\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5dce95787fa47fabf8315820a0a7935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target_week(fold): 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 452.40 Mb (69.9% reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 614.96 Mb (74.9% reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 48.62 Mb (75.0% reduction)\n",
      "[Info] shape     : (5785123, 508)\n",
      "[Info] mem       : 5666.09 Mb\n",
      "[Info] candidates: 80.3 個 / customer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "isin_trending    0.204949\n",
       "isin_recently    0.105783\n",
       "isin_popular     0.547199\n",
       "isin_lastw       0.046755\n",
       "isin_pair        0.161076\n",
       "isin_collabo     0.000940\n",
       "isin_tsne_knn    0.163379\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Precision: 0.00356\n",
      "[Info] Recall   : 0.08921\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's ndcg@12: 0.869092\tvalid_1's ndcg@12: 0.872203\n",
      "[20]\ttraining's ndcg@12: 0.871819\tvalid_1's ndcg@12: 0.873553\n",
      "[30]\ttraining's ndcg@12: 0.87319\tvalid_1's ndcg@12: 0.874054\n",
      "[40]\ttraining's ndcg@12: 0.875014\tvalid_1's ndcg@12: 0.874284\n",
      "[50]\ttraining's ndcg@12: 0.876449\tvalid_1's ndcg@12: 0.874459\n",
      "[60]\ttraining's ndcg@12: 0.878131\tvalid_1's ndcg@12: 0.874278\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's ndcg@12: 0.876598\tvalid_1's ndcg@12: 0.874589\n",
      "Evaluated only: ndcg@12\n",
      "\n",
      "target_week(fold): 3\n",
      "[Info] shape     : (6457971, 508)\n",
      "[Info] mem       : 6325.09 Mb\n",
      "[Info] candidates: 80.5 個 / customer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "isin_trending    0.202273\n",
       "isin_recently    0.099697\n",
       "isin_popular     0.567699\n",
       "isin_lastw       0.045205\n",
       "isin_pair        0.146854\n",
       "isin_collabo     0.000761\n",
       "isin_tsne_knn    0.149002\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Precision: 0.00317\n",
      "[Info] Recall   : 0.08013\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's ndcg@12: 0.882421\tvalid_1's ndcg@12: 0.870695\n",
      "[20]\ttraining's ndcg@12: 0.884415\tvalid_1's ndcg@12: 0.871806\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's ndcg@12: 0.884074\tvalid_1's ndcg@12: 0.871915\n",
      "Evaluated only: ndcg@12\n",
      "\n",
      "target_week(fold): 2\n",
      "[Info] shape     : (5713044, 508)\n",
      "[Info] mem       : 5595.49 Mb\n",
      "[Info] candidates: 75.3 個 / customer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "isin_trending    0.204008\n",
       "isin_recently    0.106206\n",
       "isin_popular     0.534979\n",
       "isin_lastw       0.047774\n",
       "isin_pair        0.154926\n",
       "isin_collabo     0.000941\n",
       "isin_tsne_knn    0.157194\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Precision: 0.00369\n",
      "[Info] Recall   : 0.08844\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's ndcg@12: 0.877809\tvalid_1's ndcg@12: 0.872287\n",
      "[20]\ttraining's ndcg@12: 0.880865\tvalid_1's ndcg@12: 0.873326\n",
      "[30]\ttraining's ndcg@12: 0.882726\tvalid_1's ndcg@12: 0.873688\n",
      "[40]\ttraining's ndcg@12: 0.884324\tvalid_1's ndcg@12: 0.874085\n",
      "[50]\ttraining's ndcg@12: 0.885533\tvalid_1's ndcg@12: 0.874392\n",
      "[60]\ttraining's ndcg@12: 0.886866\tvalid_1's ndcg@12: 0.874237\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's ndcg@12: 0.885533\tvalid_1's ndcg@12: 0.874392\n",
      "Evaluated only: ndcg@12\n",
      "\n",
      "target_week(fold): 1\n",
      "[Info] shape     : (4859354, 508)\n",
      "[Info] mem       : 4759.37 Mb\n",
      "[Info] candidates: 67.5 個 / customer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "isin_trending    0.224566\n",
       "isin_recently    0.120541\n",
       "isin_popular     0.482129\n",
       "isin_lastw       0.053294\n",
       "isin_pair        0.175578\n",
       "isin_collabo     0.001037\n",
       "isin_tsne_knn    0.178134\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Precision: 0.00405\n",
      "[Info] Recall   : 0.08628\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's ndcg@12: 0.879646\tvalid_1's ndcg@12: 0.854944\n",
      "[20]\ttraining's ndcg@12: 0.882735\tvalid_1's ndcg@12: 0.856295\n",
      "[30]\ttraining's ndcg@12: 0.88432\tvalid_1's ndcg@12: 0.856568\n",
      "[40]\ttraining's ndcg@12: 0.885921\tvalid_1's ndcg@12: 0.85684\n",
      "[50]\ttraining's ndcg@12: 0.887234\tvalid_1's ndcg@12: 0.856975\n",
      "[60]\ttraining's ndcg@12: 0.888628\tvalid_1's ndcg@12: 0.85794\n",
      "[70]\ttraining's ndcg@12: 0.89036\tvalid_1's ndcg@12: 0.857945\n",
      "[80]\ttraining's ndcg@12: 0.891488\tvalid_1's ndcg@12: 0.858521\n",
      "Early stopping, best iteration is:\n",
      "[77]\ttraining's ndcg@12: 0.891057\tvalid_1's ndcg@12: 0.858799\n",
      "Evaluated only: ndcg@12\n"
     ]
    }
   ],
   "source": [
    "# train lgb ranker\n",
    "best_iterations = []\n",
    "feature_importance_dfs = []\n",
    "oof_weeks = [4, 3, 2, 1]\n",
    "\n",
    "for i, w in enumerate(tqdm(oof_weeks)):\n",
    "    print(f\"\\ntarget_week(fold): {w}\")\n",
    "    if i == 0:\n",
    "        compress_verbose=True\n",
    "    else:\n",
    "        compress_verbose=False\n",
    "    \n",
    "    tr_df = make_data_df(transactions, w, is_labeled=True, metric_verbose=True, compress_verbose=compress_verbose)\n",
    "    val_df = make_data_df(transactions, w-1, is_labeled=True, metric_verbose=False, compress_verbose=False)\n",
    "\n",
    "    if i == 0:\n",
    "        exclude_columns = ['target_week', 'customer_id', 'article_id', 'label']\n",
    "        cols = [c for c in tr_df.columns.tolist() if c not in exclude_columns]\n",
    "        with open(f'../models/lgb_rank/{EXP}_cols.pkl', 'wb') as f:\n",
    "            pickle.dump(cols, f)\n",
    "\n",
    "    model = train(params, cols, tr_df, val_df)\n",
    "    with open(f'../models/lgb_rank/{EXP}_model_fold{w}.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    best_iterations.append(model.best_iteration)\n",
    "    feature_importance_dfs.append(pd.DataFrame({'feature': model.feature_name(), 'importance(gain)': model.feature_importance('gain'), 'fold': w}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] shape     : (4617530, 507)\n",
      "[Info] mem       : 4513.71 Mb\n",
      "[Info] candidates: 66.9 個 / customer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "isin_trending    0.207378\n",
       "isin_recently    0.111447\n",
       "isin_popular     0.498691\n",
       "isin_lastw       0.052632\n",
       "isin_pair        0.174183\n",
       "isin_collabo     0.001023\n",
       "isin_tsne_knn    0.176732\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.05850654 -4.05794132 -4.05501426 ...  2.64240301  2.64275409\n",
      "  2.64275409]\n"
     ]
    }
   ],
   "source": [
    "# predict val data\n",
    "val_df = make_data_df(transactions, 0, is_labeled=False, metric_verbose=True, compress_verbose=False)\n",
    "val_pred = predict(val_df, oof_weeks)\n",
    "print(np.sort(val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id\n",
       "80      0671607001 0436261001 0568601007 0754751001 0...\n",
       "86      0889036004 0621381012 0640021012 0880017001 0...\n",
       "107     0556255001 0399136061 0732842014 0732842021 0...\n",
       "Name: article_id, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# val top rank articles\n",
    "val_df2 = val_df.copy()\n",
    "val_pred_sr = extract_top_sr(val_df2, val_pred)\n",
    "display(val_pred_sr.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 12 popular items:\n",
      " 0909370001 0865799006 0918522001 0924243001 0448509014 0751471001 0809238001 0918292001 0762846027 0809238005 0673677002 0923758001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0     0685814003 0448509014 0918522001 0715624001 0...\n",
       "1.0     0909370001 0865799006 0924243001 0809238001 0...\n",
       "2.0     0909370001 0865799006 0918525001 0909371001 0...\n",
       "3.0     0909370001 0751471001 0673677002 0910601003 0...\n",
       "4.0     0918522001 0751471001 0751471043 0910601003 0...\n",
       "5.0     0918522001 0908799002 0896152002 0924243001 0...\n",
       "6.0     0736870001 0796210001 0908799002 0865799006 0...\n",
       "Name: top_12_popular_items, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# most popular items\n",
    "transactions_last_week = transactions.loc[transactions.week == 1]\n",
    "top12 = ' 0' + ' 0'.join(transactions_last_week.article_id.value_counts().index.astype('str')[:12])\n",
    "print(\"Top 12 popular items:\")\n",
    "print( top12 )\n",
    "\n",
    "customers['age_bin'] = pd.cut(customers['age'], bins=[10, 20, 30, 40, 50, 60, 70, 100], labels=False)\n",
    "transactions_last_week = transactions_last_week.merge(customers[['customer_id', 'age', 'age_bin']], how='left')\n",
    "popular_items = transactions_last_week.groupby('age_bin')['article_id'].value_counts()\n",
    "popular_items_dict = {}\n",
    "for index in popular_items.index.levels[0]:\n",
    "    popular_items_dict[index] = ' 0'+' 0'.join(popular_items[index][:12].index.astype('str'))\n",
    "popular_items_sr = pd.Series(popular_items_dict, name='top_12_popular_items', dtype='str')\n",
    "display(popular_items_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prediction_lgb</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>prediction_popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>0909370001 0751471001 0673677002 0910601003 07...</td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>0909370001 0751471001 0673677002 0910601003 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>0909370001 0865799006 0924243001 0809238001 04...</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0909370001 0865799006 0924243001 0809238001 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0909370001 0865799006 0924243001 0809238001 04...</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0909370001 0865799006 0924243001 0809238001 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id  \\\n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...   \n",
       "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...   \n",
       "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   \n",
       "\n",
       "                                          prediction prediction_lgb  age_bin  \\\n",
       "0  0909370001 0751471001 0673677002 0910601003 07...                     3.0   \n",
       "1  0909370001 0865799006 0924243001 0809238001 04...                     1.0   \n",
       "2  0909370001 0865799006 0924243001 0809238001 04...                     1.0   \n",
       "\n",
       "                                  prediction_popular  \n",
       "0   0909370001 0751471001 0673677002 0910601003 0...  \n",
       "1   0909370001 0865799006 0924243001 0809238001 0...  \n",
       "2   0909370001 0865799006 0924243001 0809238001 0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# val sub\n",
    "submission = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/sample_submission.csv')\n",
    "\n",
    "submission['prediction_lgb'] = submission['customer_id'].map(id_to_index_dict).map(val_pred_sr)\n",
    "submission['prediction_lgb'] = submission['prediction_lgb'].fillna('')\n",
    "\n",
    "submission['age_bin'] = submission['customer_id'].map(id_to_index_dict).map(customers.set_index('customer_id')['age_bin'])\n",
    "submission['prediction_popular'] = submission['age_bin'].map(popular_items_sr)\n",
    "submission['prediction_popular'] = submission['prediction_popular'].fillna(top12).astype('str')\n",
    "\n",
    "submission['prediction'] = submission['prediction_lgb'] + submission['prediction_popular']\n",
    "submission['prediction'] = submission['prediction'].str.strip()\n",
    "submission['prediction'] = submission['prediction'].str[:131]\n",
    "display(submission.head(3))\n",
    "submission[['customer_id', 'prediction']].to_csv(f'../submissions/{EXP}_submission_fold0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9503"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del val_df, model\n",
    "del transactions_last_week, top12, popular_items, popular_items_dict, popular_items_sr\n",
    "del val_df2, val_pred_sr, \n",
    "del submission\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] shape     : (4617530, 509)\n",
      "[Info] mem       : 4531.33 Mb\n",
      "[Info] candidates: 66.9 個 / customer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "isin_trending    0.207378\n",
       "isin_recently    0.111447\n",
       "isin_popular     0.498691\n",
       "isin_lastw       0.052632\n",
       "isin_pair        0.174183\n",
       "isin_collabo     0.001023\n",
       "isin_tsne_knn    0.176732\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Precision: 0.00445\n",
      "[Info] Recall   : 0.09620\n",
      "[10]\ttraining's ndcg@12: 0.863909\n",
      "[20]\ttraining's ndcg@12: 0.866211\n",
      "[30]\ttraining's ndcg@12: 0.868126\n",
      "[40]\ttraining's ndcg@12: 0.869721\n"
     ]
    }
   ],
   "source": [
    "# train last target_week(=0) data\n",
    "tr_df = make_data_df(transactions, week=0, is_labeled=True, metric_verbose=True, compress_verbose=False)\n",
    "\n",
    "# valがないのでアーリーストッピングが使えない\n",
    "params['num_iterations'] = int(np.mean(best_iterations))\n",
    "model = train(params, cols, tr_df)\n",
    "with open(f\"../models/lgb_rank/{EXP}_model_fold0.pkl\", 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "    \n",
    "feature_importance_dfs.append(pd.DataFrame({'feature': model.feature_name(), 'importance(gain)': model.feature_importance('gain'), 'fold': 0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance(gain)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trending_value</th>\n",
       "      <td>28193.147519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sale_max_groupby_article_ratio_1w</th>\n",
       "      <td>14008.693802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_dat</th>\n",
       "      <td>10665.028474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_pair</th>\n",
       "      <td>7429.546175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_lastw</th>\n",
       "      <td>6066.662082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sale_mean_groupby_article_ratio_1w</th>\n",
       "      <td>4879.921431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sale_1w</th>\n",
       "      <td>4162.392630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purchase_sum_groupby_customer_ratio_1w</th>\n",
       "      <td>3074.618350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_code</th>\n",
       "      <td>2289.735596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>2228.185138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sale_min_groupby_article_diff_1w</th>\n",
       "      <td>2013.458734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purchase_max_groupby_customer_ratio_1w</th>\n",
       "      <td>1895.236305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purchase_mean_groupby_customer_ratio_1w</th>\n",
       "      <td>1895.180877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sale_sum_groupby_article_ratio_2w</th>\n",
       "      <td>1708.236853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_group_name</th>\n",
       "      <td>1681.776251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purchase_1w</th>\n",
       "      <td>1677.119677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purchase_article</th>\n",
       "      <td>1676.147338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resale_customer_percent</th>\n",
       "      <td>1674.417181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resale_customer_and_week_percent</th>\n",
       "      <td>1650.786004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sale_sum_groupby_article_ratio_1w</th>\n",
       "      <td>1111.500906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         importance(gain)\n",
       "feature                                                  \n",
       "trending_value                               28193.147519\n",
       "sale_max_groupby_article_ratio_1w            14008.693802\n",
       "last_dat                                     10665.028474\n",
       "count_pair                                    7429.546175\n",
       "count_lastw                                   6066.662082\n",
       "sale_mean_groupby_article_ratio_1w            4879.921431\n",
       "sale_1w                                       4162.392630\n",
       "purchase_sum_groupby_customer_ratio_1w        3074.618350\n",
       "product_code                                  2289.735596\n",
       "age                                           2228.185138\n",
       "sale_min_groupby_article_diff_1w              2013.458734\n",
       "purchase_max_groupby_customer_ratio_1w        1895.236305\n",
       "purchase_mean_groupby_customer_ratio_1w       1895.180877\n",
       "sale_sum_groupby_article_ratio_2w             1708.236853\n",
       "product_group_name                            1681.776251\n",
       "purchase_1w                                   1677.119677\n",
       "purchase_article                              1676.147338\n",
       "resale_customer_percent                       1674.417181\n",
       "resale_customer_and_week_percent              1650.786004\n",
       "sale_sum_groupby_article_ratio_1w             1111.500906"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance_df = pd.concat(feature_importance_dfs, ignore_index=True, axis=0)\n",
    "display(feature_importance_df.groupby(['feature'])[['importance(gain)']].mean().sort_values('importance(gain)', ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2807"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del tr_df, params, model, best_iterations, feature_importance_dfs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426bb67e4a814b3c90b2894ed3265c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] shape     : (4194439, 508)\n",
      "[Info] mem       : 4108.13 Mb\n",
      "[Info] candidates: 41.9 個 / customer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "isin_trending    0.086964\n",
       "isin_recently    0.053994\n",
       "isin_popular     0.723956\n",
       "isin_lastw       0.080791\n",
       "isin_pair        0.080930\n",
       "isin_collabo     0.004045\n",
       "isin_tsne_knn    0.081984\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "customer_id\n",
       "0     0568601043 0568601006 0779781015 0858856005 0...\n",
       "1     0924243001 0866731001 0915529005 0924243002 0...\n",
       "2     0794321007 0805000001 0791587001 0924243001 0...\n",
       "Name: article_id, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict test data\n",
    "BATCH_SIZE = 100_000\n",
    "submission = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/sample_submission.csv')\n",
    "test_customers = submission['customer_id'].map(id_to_index_dict).unique()\n",
    "\n",
    "# バッチ処理\n",
    "def process(i):\n",
    "    if i == (-1 * ((-len(test_customers))//BATCH_SIZE)) - 1:\n",
    "        test_customers_batch = test_customers[i*BATCH_SIZE : ]\n",
    "    else:\n",
    "        test_customers_batch = test_customers[i*BATCH_SIZE : (i+1)*BATCH_SIZE]\n",
    "    \n",
    "    if i == 0:  # meric_verbose=True\n",
    "        test_df = make_data_df(transactions, week=-1, is_labeled=False, use_customers=test_customers_batch, metric_verbose=True, compress_verbose=False)\n",
    "    else:       # metric_verbose=False\n",
    "        test_df = make_data_df(transactions, week=-1, is_labeled=False, use_customers=test_customers_batch, metric_verbose=False, compress_verbose=False)\n",
    "\n",
    "    all_weeks = oof_weeks + [0]\n",
    "    pred = predict(test_df, all_weeks)\n",
    "    return extract_top_sr(test_df, pred)\n",
    "\n",
    "# single process execution\n",
    "preds = []\n",
    "for i in tqdm(range(-1 * ((-len(test_customers))//BATCH_SIZE)):  # 小数点以下切り上げのhack\n",
    "    preds.append(process(i))\n",
    "\n",
    "# # multi process execution\n",
    "# # cpus = cpu_count(logical=False)\n",
    "# cpus = 4\n",
    "# print('cpu(core): ', cpus)\n",
    "# preds = Parallel(n_jobs=cpus, verbose=0)( [delayed(process)(i) for i in range(len(test_customers)//BATCH_SIZE + 1)] )\n",
    "\n",
    "pred_sr = pd.concat(preds, axis=0)\n",
    "display(pred_sr.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2481"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del preds\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # most popular items\n",
    "# transactions_last_week = transactions.loc[transactions.week == 0]\n",
    "# top12 = ' 0' + ' 0'.join(transactions_last_week.article_id.value_counts().index.astype('str')[:12])\n",
    "# print(\"Top 12 popular items:\")\n",
    "# print( top12 )\n",
    "\n",
    "# customers['age_bin'] = pd.cut(customers['age'], bins=[10, 20, 30, 40, 50, 60, 70, 100], labels=False)\n",
    "# transactions_last_week = transactions_last_week.merge(customers[['customer_id', 'age', 'age_bin']], how='left')\n",
    "# popular_items = transactions_last_week.groupby('age_bin')['article_id'].value_counts()\n",
    "# popular_items_dict = {}\n",
    "# for index in popular_items.index.levels[0]:\n",
    "#     popular_items_dict[index] = ' 0'+' 0'.join(popular_items[index][:12].index.astype('str'))\n",
    "# popular_items_sr = pd.Series(popular_items_dict, name='top_12_popular_items', dtype='str')\n",
    "# popular_items_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test sub\u001b[39;00m\n\u001b[1;32m      2\u001b[0m submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../input/h-and-m-personalized-fashion-recommendations/sample_submission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m submission[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction_lgb\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msubmission\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcustomer_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mid_to_index_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_sr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m submission[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction_lgb\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m submission[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction_lgb\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# submission['age_bin'] = submission['customer_id'].map(id_to_index_dict).map(customers.set_index('customer_id')['age_bin'])\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# submission['prediction_popular'] = submission['age_bin'].map(popular_items_sr)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# submission['prediction_popular'] = submission['prediction_popular'].fillna(top12).astype('str')\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/py38_handm/lib/python3.8/site-packages/pandas/core/series.py:4237\u001b[0m, in \u001b[0;36mSeries.map\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   4162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg, na_action\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m   4163\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4164\u001b[0m \u001b[38;5;124;03m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[1;32m   4165\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4235\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[1;32m   4236\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_values, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4239\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4240\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/py38_handm/lib/python3.8/site-packages/pandas/core/base.py:852\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cat\u001b[38;5;241m.\u001b[39mmap(mapper)\n\u001b[1;32m    850\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m--> 852\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mmapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m new_values \u001b[38;5;241m=\u001b[39m algorithms\u001b[38;5;241m.\u001b[39mtake_nd(mapper\u001b[38;5;241m.\u001b[39m_values, indexer)\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_values\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/py38_handm/lib/python3.8/site-packages/pandas/core/indexes/base.py:3721\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3718\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[1;32m   3720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 3721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[1;32m   3723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3724\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "# test sub\n",
    "submission = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/sample_submission.csv')\n",
    "\n",
    "submission['prediction_lgb'] = submission['customer_id'].map(id_to_index_dict).map(pred_sr)\n",
    "submission['prediction_lgb'] = submission['prediction_lgb'].fillna('')\n",
    "\n",
    "# submission['age_bin'] = submission['customer_id'].map(id_to_index_dict).map(customers.set_index('customer_id')['age_bin'])\n",
    "# submission['prediction_popular'] = submission['age_bin'].map(popular_items_sr)\n",
    "# submission['prediction_popular'] = submission['prediction_popular'].fillna(top12).astype('str')\n",
    "\n",
    "submission['prediction'] = submission['prediction_lgb']\n",
    "submission['prediction'] = submission['prediction'].str.strip()\n",
    "submission['prediction'] = submission['prediction'].str[:131]\n",
    "display(submission.head(3))\n",
    "submission[['customer_id', 'prediction']].to_csv(f'../submissions/{EXP}_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f804528fa1bcda80b2057737773baa2134c5be7e013153f88e69abab752260b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
